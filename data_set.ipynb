{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9eVQIm5LuxHV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_html_content(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches the HTML content from the given URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to fetch the HTML content from.\n",
        "\n",
        "    Returns:\n",
        "        str: The HTML content of the page.\n",
        "\n",
        "    Raises:\n",
        "        RequestException: If the request fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n",
        "        return response.text\n",
        "    except RequestException as e:\n",
        "        print(f\"Failed to retrieve the webpage: {e}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_page(page_number):\n",
        "    url = f'https://www.rottentomatoes.com/browse/movies_at_home/?page={page_number}'\n",
        "    response = requests.get(url)\n",
        "    return response.text if response.status_code == 200 else None"
      ],
      "metadata": {
        "id": "xMu0Esw2u32S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_movies(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    tiles = soup.find_all('div', class_='js-tile-link')\n",
        "    movie_data = []\n",
        "    for tile in tiles:\n",
        "        title_tag = tile.find('span', {'data-qa': 'discovery-media-list-item-title'})\n",
        "        date_tag = tile.find('span', {'data-qa': 'discovery-media-list-item-start-date'})\n",
        "        score_tags = tile.find('score-pairs-deprecated')\n",
        "        if title_tag and date_tag and score_tags:\n",
        "            title = title_tag.get_text(strip=True)\n",
        "            streaming_date = date_tag.get_text(strip=True)\n",
        "            critic_score = score_tags.get('criticsscore')\n",
        "            audience_score = score_tags.get('audiencescore')\n",
        "            url_tag = tile.find('a', {'data-qa': 'discovery-media-list-item-caption'})\n",
        "            url = 'https://www.rottentomatoes.com' + url_tag['href'] if url_tag and 'href' in url_tag.attrs else 'No URL'\n",
        "            movie_data.append([title, url, critic_score, audience_score, streaming_date])\n",
        "    return movie_data"
      ],
      "metadata": {
        "id": "9e6bAwQuu5UK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_movies_to_csv(movies):\n",
        "    with open('movies.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Title', 'URL', 'Critic Score', 'Audience Score', 'Streaming Date'])\n",
        "        for movie in movies:\n",
        "            writer.writerow(movie)"
      ],
      "metadata": {
        "id": "fsITa2QOu7Ky"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    all_movies = []\n",
        "    page = 1\n",
        "    while len(all_movies) < 5500:\n",
        "        html_content = fetch_page(page)\n",
        "        if not html_content:\n",
        "            print(\"No more pages or network error.\")\n",
        "            break\n",
        "        movies = parse_movies(html_content)\n",
        "        all_movies.extend(movies)\n",
        "        print(f\"Retrieved {len(movies)} movies from page {page}. Total: {len(all_movies)}\")\n",
        "        page += 1\n",
        "        if not movies:\n",
        "            print(\"No more movies found, stopping.\")\n",
        "            break\n",
        "\n",
        "    save_movies_to_csv(all_movies)\n",
        "    print(\"Movies saved to CSV.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Reading the CSV file using pandas\n",
        "df = pd.read_csv(\"movies.csv\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfI9yquDu9PT",
        "outputId": "42f5ea0d-a1a3-4f57-8354-e04ca9168324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 16 movies from page 1. Total: 16\n",
            "Retrieved 36 movies from page 2. Total: 52\n",
            "Retrieved 62 movies from page 3. Total: 114\n",
            "Retrieved 88 movies from page 4. Total: 202\n",
            "Retrieved 110 movies from page 5. Total: 312\n",
            "Retrieved 110 movies from page 6. Total: 422\n",
            "Retrieved 110 movies from page 7. Total: 532\n",
            "Retrieved 110 movies from page 8. Total: 642\n",
            "Retrieved 110 movies from page 9. Total: 752\n",
            "Retrieved 110 movies from page 10. Total: 862\n",
            "Retrieved 110 movies from page 11. Total: 972\n",
            "Retrieved 110 movies from page 12. Total: 1082\n",
            "Retrieved 110 movies from page 13. Total: 1192\n",
            "Retrieved 110 movies from page 14. Total: 1302\n",
            "Retrieved 110 movies from page 15. Total: 1412\n",
            "Retrieved 110 movies from page 16. Total: 1522\n",
            "Retrieved 110 movies from page 17. Total: 1632\n",
            "Retrieved 110 movies from page 18. Total: 1742\n",
            "Retrieved 110 movies from page 19. Total: 1852\n",
            "Retrieved 110 movies from page 20. Total: 1962\n",
            "Retrieved 110 movies from page 21. Total: 2072\n",
            "Retrieved 110 movies from page 22. Total: 2182\n",
            "Retrieved 110 movies from page 23. Total: 2292\n",
            "Retrieved 110 movies from page 24. Total: 2402\n",
            "Retrieved 110 movies from page 25. Total: 2512\n",
            "Retrieved 110 movies from page 26. Total: 2622\n",
            "Retrieved 110 movies from page 27. Total: 2732\n"
          ]
        }
      ]
    }
  ]
}